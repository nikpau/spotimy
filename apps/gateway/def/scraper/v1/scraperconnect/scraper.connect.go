// Code generated by protoc-gen-connect-go. DO NOT EDIT.
//
// Source: scraper/v1/scraper.proto

package scraperconnect

import (
	context "context"
	errors "errors"
	connect_go "github.com/bufbuild/connect-go"
	v1 "github.com/nikpau/spotimy/apps/gateway/def/scraper/v1"
	http "net/http"
	strings "strings"
)

// This is a compile-time assertion to ensure that this generated file and the connect package are
// compatible. If you get a compiler error that this constant is not defined, this code was
// generated with a version of connect newer than the one compiled into your binary. You can fix the
// problem by either regenerating this code with an older version of connect or updating the connect
// version compiled into your binary.
const _ = connect_go.IsAtLeastVersion0_1_0

const (
	// ScraperServiceName is the fully-qualified name of the ScraperService service.
	ScraperServiceName = "scraper.v1.ScraperService"
)

// ScraperServiceClient is a client for the scraper.v1.ScraperService service.
type ScraperServiceClient interface {
	Scrape(context.Context, *connect_go.Request[v1.ScrapeRequest]) (*connect_go.Response[v1.ScrapeResponse], error)
}

// NewScraperServiceClient constructs a client for the scraper.v1.ScraperService service. By
// default, it uses the Connect protocol with the binary Protobuf Codec, asks for gzipped responses,
// and sends uncompressed requests. To use the gRPC or gRPC-Web protocols, supply the
// connect.WithGRPC() or connect.WithGRPCWeb() options.
//
// The URL supplied here should be the base URL for the Connect or gRPC server (for example,
// http://api.acme.com or https://acme.com/grpc).
func NewScraperServiceClient(httpClient connect_go.HTTPClient, baseURL string, opts ...connect_go.ClientOption) ScraperServiceClient {
	baseURL = strings.TrimRight(baseURL, "/")
	return &scraperServiceClient{
		scrape: connect_go.NewClient[v1.ScrapeRequest, v1.ScrapeResponse](
			httpClient,
			baseURL+"/scraper.v1.ScraperService/Scrape",
			opts...,
		),
	}
}

// scraperServiceClient implements ScraperServiceClient.
type scraperServiceClient struct {
	scrape *connect_go.Client[v1.ScrapeRequest, v1.ScrapeResponse]
}

// Scrape calls scraper.v1.ScraperService.Scrape.
func (c *scraperServiceClient) Scrape(ctx context.Context, req *connect_go.Request[v1.ScrapeRequest]) (*connect_go.Response[v1.ScrapeResponse], error) {
	return c.scrape.CallUnary(ctx, req)
}

// ScraperServiceHandler is an implementation of the scraper.v1.ScraperService service.
type ScraperServiceHandler interface {
	Scrape(context.Context, *connect_go.Request[v1.ScrapeRequest]) (*connect_go.Response[v1.ScrapeResponse], error)
}

// NewScraperServiceHandler builds an HTTP handler from the service implementation. It returns the
// path on which to mount the handler and the handler itself.
//
// By default, handlers support the Connect, gRPC, and gRPC-Web protocols with the binary Protobuf
// and JSON codecs. They also support gzip compression.
func NewScraperServiceHandler(svc ScraperServiceHandler, opts ...connect_go.HandlerOption) (string, http.Handler) {
	mux := http.NewServeMux()
	mux.Handle("/scraper.v1.ScraperService/Scrape", connect_go.NewUnaryHandler(
		"/scraper.v1.ScraperService/Scrape",
		svc.Scrape,
		opts...,
	))
	return "/scraper.v1.ScraperService/", mux
}

// UnimplementedScraperServiceHandler returns CodeUnimplemented from all methods.
type UnimplementedScraperServiceHandler struct{}

func (UnimplementedScraperServiceHandler) Scrape(context.Context, *connect_go.Request[v1.ScrapeRequest]) (*connect_go.Response[v1.ScrapeResponse], error) {
	return nil, connect_go.NewError(connect_go.CodeUnimplemented, errors.New("scraper.v1.ScraperService.Scrape is not implemented"))
}
